# Stream 数据流

当内存中无法一次装下需要处理的数据时，或者一边读取一边处理更加高效时，我们就需要用到数据流。NodeJS 中通过各种Stream来提供对数据流的操作。

var rs = fs.createReadStream(pathname); // 为数据来源创建一个只读数据流
var ws = fs.createWriteStream(dst); // 为数据目标创建一个只写数据流

rs.on('data', function(chunk) {
    if (ws.write(chunk) === false) {
        rs.pause(); // 停止数据读取
    }
});
rs.on('end', function() {
    ws.end();
});
ws.on('drain', function() {
    rs.resume(); // 恢复数据读取
});

如果写入速度跟不上读取速度的话，只写数据流内部的缓存会爆仓。
我们可以根据 .write 方法的返回值来判断传入的数据是写入目标了，还是临时放在了缓存了，并根据 drain 事件来判断什么时候只写数据流已经将缓存中的数据写入目标，可以传入下一个待写数据了。

Stream 基于事件机制工作，所有 Stream 的实例都继承于 NodeJS 提供的 EventEmitter。

以上代码实现了数据从只读数据流到只写数据流的搬运，并包括了防爆仓控制。
因为这种使用场景很多，例如上边的大文件拷贝程序，NodeJS 直接提供了 .pipe 方法来做这件事情，其内部实现方式与上边的代码类似。

fs.createReadStream(pathname).pipe(fs.createWriteStream(dst));


Stream 的其他事件

.on('readable', function() {
    // 读取文件时，只要文件是可读的，就会触发该事件
});

.on('close', function() {
    // 整个流传输结束关闭的时候会触发该事件
});

.on('error', function(e) {
    // 流传输错误时触发该事件
    console.log('data read error: ' + e);
});


